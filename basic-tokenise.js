define(['utils', 'models', 'fake6502', 'promise'],
    function (utils, models, Fake6502) {
        "use strict";

        function create() {
            var cpu = Fake6502.fake6502(models.basicOnly);
            var callTokeniser = function (line) {
                // Address of the tokenisation subroutine in the Master's BASIC ROM.
                // With thanks to http://8bs.com/basic/basic4-8db2.htm
                const tokeniseBASIC = 0x8db2;
                // Address of the instruction to intercept where the tail is copied down.
                const copyIntercept = 0x8ea1;
                // Set the stack top to this, then execute until the CPU pops past this.
                const stackTop = 0xf0;
                // Address to inject the BASIC program text at.
                const workSpace = 0x1000;
                // Pointer to the program text.
                const textPtrLo = 0x37;
                const textPtrHi = 0x38;

                cpu.pc = tokeniseBASIC;
                cpu.s = stackTop;
                var offset = workSpace;
                // Set flags to indicate that we're at the start of a statement
                // but have already processed the line number.
                cpu.writemem(0x3b, 0x00);
                cpu.writemem(0x3c, 0x00);
                cpu.writemem(textPtrLo, offset & 0xff);
                cpu.writemem(textPtrHi, (offset >>> 8) & 0xff);
                // Set the paged ROM latch to page in the BASIC.
                cpu.writemem(0xfe30, 12);
                for (var i = 0; i < line.length; ++i) {
                    cpu.writemem(offset + i, line.charCodeAt(i));
                }
                cpu.writemem(offset + line.length, 0x0d);
                var safety = 20 * 1000 * 1000;
                var result = "";
                while (cpu.s <= stackTop) {
                    cpu.execute(1);
                    if (--safety === 0) {
                        break;
                    }
                    if (cpu.pc === copyIntercept) {
                        // Intercept the subroutine in the BASIC ROM which replaces a keyword
                        // with a token and copies down the tail of the line.  The 6502 code
                        // uses the Y register to index the copy and fails if the untokenised
                        // tail is longer than 255 bytes.  It also makes tokenisation O(nÂ²)
                        // for a line with a lot of tokens.
                        //
                        // Instead we copy out the newly processed part and advance the pointer
                        // to the unprocessed part.
                        let to = cpu.readmemZpStack(textPtrHi) << 8 | cpu.readmemZpStack(textPtrLo);
                        while (offset < to) {
                            result += String.fromCharCode(cpu.readmem(offset));
                            offset++;
                        }
                        result += String.fromCharCode(cpu.a);
                        offset += cpu.y;
                        cpu.writememZpStack(textPtrLo, offset & 0xff);
                        cpu.writememZpStack(textPtrHi, (offset >>> 8) & 0xff);
                        ++offset;
                        // Skip over the JSR instruction.
                        cpu.pc += 3;
                    }
                }
                for (i = offset; cpu.readmem(i) !== 0x0d; ++i) {
                    result += String.fromCharCode(cpu.readmem(i));
                }
                if (safety === 0) {
                    throw new Error("Unable to tokenize '" + line + "' - got as far as '" + result + "' pc=" + utils.hexword(cpu.pc));
                }
                return result;
            };
            var lineRe = /^([0-9]+)?(.*)/;
            var tokeniseLine = function (line, lineNumIfNotSpec) {
                var lineSplit = line.match(lineRe);
                var lineNum = lineSplit[1] ? parseInt(lineSplit[1]) : lineNumIfNotSpec;
                var tokens = callTokeniser(lineSplit[2]);
                if (tokens.length > 251) {
                    throw new Error("Line " + lineNum + " tokenised length " + tokens.length + " > 251 bytes");
                }
                return '\r' +
                    String.fromCharCode((lineNum >>> 8) & 0xff) +
                    String.fromCharCode(lineNum & 0xff) +
                    String.fromCharCode(tokens.length + 4) + tokens;
            };
            var tokenise = function (text) {
                var result = "";
                text.split("\n").forEach(function (line, i) {
                    if (line) {
                        result += tokeniseLine(line, 10 + i * 10);
                    }
                });
                return result + "\r\xff";
            };
            return cpu.initialise().then(function () {
                return Promise.resolve({
                    tokenise: tokenise
                });
            });
        }

        return {
            create: create
        };
    });
